// MARK: - å®Œæ•´ä¿®æ­£çš„ ChatGPT ç®¡ç†å™¨
import SwiftUI
import Speech
import AVFoundation

// MARK: - æ•¸æ“šæ¨¡å‹
struct ChatMessage: Identifiable, Codable {
    let id = UUID()
    let content: String
    let isUser: Bool
    let timestamp: Date
    
    private enum CodingKeys: String, CodingKey {
        case content, isUser, timestamp
    }
}

struct EmotionAnalysis: Codable {
    let stressLevel: Double // 0-100
    let emotionScore: Double // -100 åˆ° 100ï¼Œè² æ•¸è¡¨ç¤ºè² é¢æƒ…ç·’
    let detectedKeywords: [String]
    let confidence: Double // 0-1
    
    var emotionType: String {
        switch emotionScore {
        case 50...100:
            return "éå¸¸é–‹å¿ƒ"
        case 20..<50:
            return "é–‹å¿ƒ"
        case -20..<20:
            return "å¹³éœ"
        case -50..<(-20):
            return "æœ‰äº›é›£é"
        default:
            return "å¾ˆé›£é"
        }
    }
    
    var stressCategory: String {
        switch stressLevel {
        case 0..<25:
            return "ä½å£“åŠ›"
        case 25..<50:
            return "ä¸­ç­‰å£“åŠ›"
        case 50..<75:
            return "é«˜å£“åŠ›"
        default:
            return "æ¥µé«˜å£“åŠ›"
        }
    }
    
    var stressCategoryColor: Color {
        switch stressLevel {
        case 0..<25:
            return .green
        case 25..<50:
            return .yellow
        case 50..<75:
            return .orange
        default:
            return .red
        }
    }
}


// MARK: - SimpleChatGPTManager (ä¿®æ­£ç‰ˆ)
class SimpleChatGPTManager: NSObject, ObservableObject {
    @Published var isListening = false
    @Published var isProcessing = false
    @Published var currentResponse = ""
    @Published var conversationHistory: [ChatMessage] = []
    @Published var detectedEmotion: EmotionAnalysis?
    @Published var speechError: String?
    @Published var apiError: String?
    @Published var hasValidAPIKey: Bool = false
    
    private let speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: "zh-TW"))
    private var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    private var recognitionTask: SFSpeechRecognitionTask?
    private let audioEngine = AVAudioEngine()
    private let synthesizer = AVSpeechSynthesizer()
    
    // API é…ç½®
    private var apiKey: String = "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"
    private let apiURL = "https://api.openai.com/v1/chat/completions"
    
    override init() {
        super.init()
        setupSpeech()
        setupInitialGreeting()
        loadAPIKey()
    }
    
    // MARK: - API Key ç®¡ç†
    func setAPIKey(_ key: String) {
        self.apiKey = key
        hasValidAPIKey = !key.isEmpty && key.hasPrefix("sk-")
        saveAPIKey(key)
        if hasValidAPIKey {
            setupInitialGreeting()
        }
    }
    
    private func saveAPIKey(_ key: String) {
        UserDefaults.standard.set(key, forKey: "openai_api_key")
    }
    
    private func loadAPIKey() {
        if let savedKey = UserDefaults.standard.string(forKey: "openai_api_key") {
            apiKey = savedKey
            hasValidAPIKey = !savedKey.isEmpty && savedKey.hasPrefix("sk-")
        }
    }
    
    func clearAPIKey() {
        apiKey = ""
        hasValidAPIKey = false
        UserDefaults.standard.removeObject(forKey: "openai_api_key")
        clearConversation()
    }
    
    // MARK: - åˆå§‹åŒ–
    private func setupInitialGreeting() {
        conversationHistory.removeAll()
        let greeting = ChatMessage(
            content: hasValidAPIKey ?
                "å—¨ï¼æˆ‘æ˜¯ Clear ğŸ’™ ä»Šå¤©éå¾—æ€éº¼æ¨£ï¼Ÿ" :
                "å—¨ï¼æˆ‘æ˜¯ Clear ğŸ’™ è«‹å…ˆè¨­ç½® API Key ä¾†å•Ÿç”¨å°è©±åŠŸèƒ½ã€‚",
            isUser: false,
            timestamp: Date()
        )
        conversationHistory.append(greeting)
    }
    
    // MARK: - ä¿®æ­£çš„èªéŸ³è¨­ç½®
    private func setupSpeech() {
        // èªéŸ³è­˜åˆ¥æ¬Šé™
        SFSpeechRecognizer.requestAuthorization { authStatus in
            DispatchQueue.main.async {
                switch authStatus {
                case .authorized:
                    print("èªéŸ³è­˜åˆ¥å·²æˆæ¬Š")
                case .denied, .restricted, .notDetermined:
                    self.speechError = "éœ€è¦èªéŸ³è­˜åˆ¥æ¬Šé™æ‰èƒ½ä½¿ç”¨èªéŸ³åŠŸèƒ½"
                @unknown default:
                    break
                }
            }
        }
        
        // ä¿®æ­£çš„éº¥å…‹é¢¨æ¬Šé™è«‹æ±‚ - å…¼å®¹èˆŠç‰ˆæœ¬
        requestMicrophonePermission()
    }
    
    private func requestMicrophonePermission() {
        if #available(iOS 17.0, *) {
            // iOS 17+ ä½¿ç”¨æ–°çš„ API - ä¿®æ­£ç‰ˆæœ¬
            Task {
                let granted = await AVAudioApplication.requestRecordPermission()
                await MainActor.run {
                    if !granted {
                        self.speechError = "éœ€è¦éº¥å…‹é¢¨æ¬Šé™æ‰èƒ½éŒ„éŸ³"
                    }
                }
            }
        } else {
            // iOS 16 åŠæ›´æ—©ç‰ˆæœ¬ä½¿ç”¨èˆŠçš„ API
            AVAudioSession.sharedInstance().requestRecordPermission { granted in
                DispatchQueue.main.async {
                    if !granted {
                        self.speechError = "éœ€è¦éº¥å…‹é¢¨æ¬Šé™æ‰èƒ½éŒ„éŸ³"
                    }
                }
            }
        }
    }
    
    // MARK: - èªéŸ³è­˜åˆ¥
    func startListening() {
        guard hasValidAPIKey else {
            apiError = "è«‹å…ˆè¨­ç½® OpenAI API Key"
            return
        }
        
        stopListening()
        
        guard let speechRecognizer = speechRecognizer, speechRecognizer.isAvailable else {
            speechError = "èªéŸ³è­˜åˆ¥åŠŸèƒ½æš«æ™‚ä¸å¯ç”¨"
            return
        }
        
        isListening = true
        speechError = nil
        
        Task {
            do {
                let audioSession = AVAudioSession.sharedInstance()
                try audioSession.setCategory(.record, mode: .measurement, options: .duckOthers)
                try audioSession.setActive(true, options: .notifyOthersOnDeactivation)
                
                await MainActor.run {
                    self.startSpeechRecognition()
                }
            } catch {
                await MainActor.run {
                    self.speechError = "éŸ³é »è¨­ç½®éŒ¯èª¤: \(error.localizedDescription)"
                    self.isListening = false
                }
            }
        }
    }
    
    @MainActor
    private func startSpeechRecognition() {
        recognitionRequest = SFSpeechAudioBufferRecognitionRequest()
        guard let recognitionRequest = recognitionRequest else {
            speechError = "ç„¡æ³•å‰µå»ºèªéŸ³è­˜åˆ¥è«‹æ±‚"
            return
        }
        
        recognitionRequest.shouldReportPartialResults = true
        
        let inputNode = audioEngine.inputNode
        let recordingFormat = inputNode.outputFormat(forBus: 0)
        
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { buffer, _ in
            recognitionRequest.append(buffer)
        }
        
        do {
            audioEngine.prepare()
            try audioEngine.start()
            
            recognitionTask = speechRecognizer?.recognitionTask(with: recognitionRequest) { [weak self] result, error in
                DispatchQueue.main.async {
                    if let result = result {
                        let transcription = result.bestTranscription.formattedString
                        
                        if result.isFinal {
                            self?.processUserInput(transcription)
                            self?.stopListening()
                        }
                    }
                    
                    if let error = error {
                        self?.speechError = "èªéŸ³è­˜åˆ¥éŒ¯èª¤: \(error.localizedDescription)"
                        self?.stopListening()
                    }
                }
            }
        } catch {
            speechError = "èªéŸ³å¼•æ“å•Ÿå‹•å¤±æ•—: \(error.localizedDescription)"
            isListening = false
        }
    }
    
    func stopListening() {
        audioEngine.stop()
        audioEngine.inputNode.removeTap(onBus: 0)
        recognitionRequest?.endAudio()
        recognitionTask?.cancel()
        
        recognitionRequest = nil
        recognitionTask = nil
        isListening = false
        
        Task {
            do {
                try AVAudioSession.sharedInstance().setActive(false, options: .notifyOthersOnDeactivation)
            } catch {
                print("éŸ³é »æœƒè©±åœæ­¢éŒ¯èª¤: \(error)")
            }
        }
    }
    
    // MARK: - è¨Šæ¯è™•ç†
    private func processUserInput(_ text: String) {
        guard !text.isEmpty else { return }
        guard hasValidAPIKey else {
            apiError = "è«‹å…ˆè¨­ç½® OpenAI API Key"
            return
        }
        
        let userMessage = ChatMessage(content: text, isUser: true, timestamp: Date())
        conversationHistory.append(userMessage)
        
        isProcessing = true
        apiError = nil
        
        Task {
            await sendToChatGPT(message: text)
        }
    }
    
    @MainActor
    private func sendToChatGPT(message: String) async {
        guard !apiKey.isEmpty else {
            apiError = "ç„¡æ³•å–å¾— API Key"
            isProcessing = false
            return
        }
        
        do {
            let response = try await callChatGPTAPI(message: message)
            let aiMessage = ChatMessage(content: response.cleanContent, isUser: false, timestamp: Date())
            conversationHistory.append(aiMessage)
            currentResponse = response.cleanContent
            
            if let emotionAnalysis = parseEmotionAnalysis(from: response.fullContent) {
                detectedEmotion = emotionAnalysis
                print("ğŸ§  AI æƒ…ç·’åˆ†æ: \(emotionAnalysis.emotionType), å£“åŠ›: \(Int(emotionAnalysis.stressLevel))%")
            }
            
            isProcessing = false
            speakResponse(response.cleanContent)
            
        } catch {
            handleAPIError(error)
        }
    }
    
    private func handleAPIError(_ error: Error) {
        if let chatError = error as? ChatGPTError {
            apiError = chatError.errorDescription
            switch chatError {
            case .invalidAPIKey:
                hasValidAPIKey = false
            case .networkError:
                provideFallbackResponse(for: conversationHistory.last?.content ?? "")
            default:
                break
            }
        } else {
            apiError = "æœªçŸ¥éŒ¯èª¤: \(error.localizedDescription)"
            provideFallbackResponse(for: conversationHistory.last?.content ?? "")
        }
        isProcessing = false
    }
    
    private func callChatGPTAPI(message: String) async throws -> (fullContent: String, cleanContent: String) {
        guard let url = URL(string: apiURL) else {
            throw ChatGPTError.invalidURL
        }
        
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.setValue("Bearer \(apiKey)", forHTTPHeaderField: "Authorization")
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
        request.timeoutInterval = 30
        
        let systemPrompt = """
        ä½ æ˜¯ã€ŒClearã€ï¼Œä¸€å€‹æº«æš–çš„ AI æƒ…ç·’é™ªä¼´åŠ©æ‰‹ã€‚ç”¨ç¹é«”ä¸­æ–‡å›æ‡‰ï¼Œèªæ°£è¦ªåˆ‡è‡ªç„¶ã€‚

        è«‹åœ¨å›æ‡‰æœ€å¾ŒåŠ ä¸Šæƒ…ç·’åˆ†æï¼š
        [EMOTION_ANALYSIS]
        STRESS: [0-100çš„å£“åŠ›æŒ‡æ•¸]
        EMOTION: [-100åˆ°100çš„æƒ…ç·’æŒ‡æ•¸]
        KEYWORDS: [é—œéµè©1,é—œéµè©2,é—œéµè©3]
        [/EMOTION_ANALYSIS]
        
        ä¿æŒå›æ‡‰ç°¡æ½”(50-100å­—)ï¼Œå¯Œæœ‰åŒç†å¿ƒã€‚
        """
        
        var messages: [[String: String]] = [
            ["role": "system", "content": systemPrompt]
        ]
        
        // åŒ…å«æœ€è¿‘3æ¢å°è©±ä½œç‚ºä¸Šä¸‹æ–‡
        let recentHistory = conversationHistory.suffix(3)
        for chatMessage in recentHistory {
            let role = chatMessage.isUser ? "user" : "assistant"
            var content = chatMessage.content
            content = cleanResponseContent(content)
            messages.append(["role": role, "content": content])
        }
        
        messages.append(["role": "user", "content": message])
        
        let requestBody: [String: Any] = [
            "model": "gpt-3.5-turbo",
            "messages": messages,
            "max_tokens": 200,
            "temperature": 0.7
        ]
        
        let jsonData = try JSONSerialization.data(withJSONObject: requestBody)
        request.httpBody = jsonData
        
        let (data, response) = try await URLSession.shared.data(for: request)
        
        guard let httpResponse = response as? HTTPURLResponse else {
            throw ChatGPTError.invalidResponse
        }
        
        guard httpResponse.statusCode == 200 else {
            if httpResponse.statusCode == 401 {
                throw ChatGPTError.invalidAPIKey
            }
            throw ChatGPTError.httpError(httpResponse.statusCode)
        }
        
        guard let jsonResponse = try JSONSerialization.jsonObject(with: data) as? [String: Any],
              let choices = jsonResponse["choices"] as? [[String: Any]],
              let firstChoice = choices.first,
              let messageDict = firstChoice["message"] as? [String: Any],
              let content = messageDict["content"] as? String else {
            throw ChatGPTError.parsingError
        }
        
        let cleanContent = cleanResponseContent(content)
        return (fullContent: content, cleanContent: cleanContent)
    }
    
    private func cleanResponseContent(_ content: String) -> String {
        let pattern = "\\[EMOTION_ANALYSIS\\][\\s\\S]*?\\[/EMOTION_ANALYSIS\\]"
        guard let regex = try? NSRegularExpression(pattern: pattern, options: .caseInsensitive) else {
            return content.trimmingCharacters(in: .whitespacesAndNewlines)
        }
        
        let range = NSRange(location: 0, length: content.count)
        let cleanContent = regex.stringByReplacingMatches(in: content, options: [], range: range, withTemplate: "")
        
        return cleanContent.trimmingCharacters(in: .whitespacesAndNewlines)
    }
    
    private func parseEmotionAnalysis(from content: String) -> EmotionAnalysis? {
        let pattern = "\\[EMOTION_ANALYSIS\\][\\s\\S]*?STRESS:\\s*(\\d+)[\\s\\S]*?EMOTION:\\s*(-?\\d+)[\\s\\S]*?KEYWORDS:\\s*([^\\]]*)[\\s\\S]*?\\[/EMOTION_ANALYSIS\\]"
        
        guard let regex = try? NSRegularExpression(pattern: pattern, options: .caseInsensitive),
              let match = regex.firstMatch(in: content, options: [], range: NSRange(location: 0, length: content.count)) else {
            return createFallbackEmotionAnalysis()
        }
        
        let stressRange = Range(match.range(at: 1), in: content)
        let emotionRange = Range(match.range(at: 2), in: content)
        let keywordsRange = Range(match.range(at: 3), in: content)
        
        guard let stressRange = stressRange,
              let emotionRange = emotionRange,
              let keywordsRange = keywordsRange else {
            return createFallbackEmotionAnalysis()
        }
        
        let stressString = String(content[stressRange])
        let emotionString = String(content[emotionRange])
        let keywordsString = String(content[keywordsRange])
        
        guard let stressLevel = Double(stressString),
              let emotionScore = Double(emotionString) else {
            return createFallbackEmotionAnalysis()
        }
        
        let keywords = keywordsString.components(separatedBy: ",").map { $0.trimmingCharacters(in: .whitespacesAndNewlines) }
        
        return EmotionAnalysis(
            stressLevel: min(100, max(0, stressLevel)),
            emotionScore: min(100, max(-100, emotionScore)),
            detectedKeywords: keywords.filter { !$0.isEmpty },
            confidence: 0.85
        )
    }
    
    private func createFallbackEmotionAnalysis() -> EmotionAnalysis {
        let stressKeywords = ["å£“åŠ›", "ç·Šå¼µ", "ç„¦æ…®", "ç´¯", "ç–²æ†Š", "ç…©èº", "å¿™"]
        let happyKeywords = ["é–‹å¿ƒ", "å¿«æ¨‚", "èˆˆå¥®", "æ»¿è¶³", "æ„‰å¿«", "é«˜èˆˆ", "æ£’"]
        let sadKeywords = ["é›£é", "æ†‚é¬±", "æ²®å–ª", "å¤±æœ›", "æ‚²å‚·", "ä½è½"]
        
        var stressLevel: Double = 30
        var emotionScore: Double = 0
        var foundKeywords: [String] = []
        
        let userMessages = conversationHistory.filter { $0.isUser }.suffix(3)
        let recentText = userMessages.map { $0.content }.joined(separator: " ")
        
        for keyword in stressKeywords {
            if recentText.contains(keyword) {
                stressLevel += 15
                foundKeywords.append(keyword)
            }
        }
        
        for keyword in happyKeywords {
            if recentText.contains(keyword) {
                emotionScore += 20
                foundKeywords.append(keyword)
            }
        }
        
        for keyword in sadKeywords {
            if recentText.contains(keyword) {
                emotionScore -= 20
                foundKeywords.append(keyword)
            }
        }
        
        return EmotionAnalysis(
            stressLevel: min(100, max(0, stressLevel)),
            emotionScore: min(100, max(-100, emotionScore)),
            detectedKeywords: Array(Set(foundKeywords)),
            confidence: 0.6
        )
    }
    
    private func provideFallbackResponse(for input: String) {
        let fallbackResponse: String
        
        if input.contains("å£“åŠ›") || input.contains("ç´¯") {
            fallbackResponse = "è½èµ·ä¾†ä½ æœ€è¿‘å¾ˆè¾›è‹¦å‘¢ã€‚é›–ç„¶ç¶²è·¯æœ‰é»å•é¡Œï¼Œä½†æˆ‘é‚„æ˜¯æƒ³é™ªä¼´ä½ ã€‚è¦ä¸è¦è©¦è©¦æ·±å‘¼å¸ï¼ŸğŸ’™"
        } else if input.contains("é–‹å¿ƒ") || input.contains("é«˜èˆˆ") {
            fallbackResponse = "å¤ªå¥½äº†ï¼ä½ çš„å¿«æ¨‚ä¹Ÿæ„ŸæŸ“äº†æˆ‘å‘¢ ğŸ˜Š"
        } else if input.contains("é›£é") || input.contains("æ†‚é¬±") {
            fallbackResponse = "æˆ‘èƒ½æ„Ÿå—åˆ°ä½ çš„æƒ…ç·’...è«‹è¨˜ä½ä½ ä¸¦ä¸å­¤å–®ï¼Œæˆ‘åœ¨é€™è£¡ ğŸ¤—"
        } else {
            fallbackResponse = "è¬è¬ä½ é¡˜æ„å’Œæˆ‘åˆ†äº«ã€‚é›–ç„¶ç¶²è·¯æœ‰é»å•é¡Œï¼Œä½†æˆ‘é‚„æ˜¯å¾ˆçæƒœå’Œä½ çš„å°è©± ğŸ’™"
        }
        
        let aiMessage = ChatMessage(content: fallbackResponse, isUser: false, timestamp: Date())
        conversationHistory.append(aiMessage)
        currentResponse = fallbackResponse
        speakResponse(fallbackResponse)
    }
    
    private func speakResponse(_ text: String) {
        let utterance = AVSpeechUtterance(string: text)
        utterance.voice = AVSpeechSynthesisVoice(language: "zh-TW")
        utterance.rate = 0.5
        utterance.pitchMultiplier = 1.1
        utterance.volume = 0.8
        
        synthesizer.speak(utterance)
    }
    
    // MARK: - å…¬é–‹æ–¹æ³•
    func sendTextMessage(_ text: String) {
        processUserInput(text)
    }
    
    func clearConversation() {
        conversationHistory.removeAll()
        detectedEmotion = nil
        currentResponse = ""
        apiError = nil
        setupInitialGreeting()
    }
    
    func getConversationSummary() -> String {
        guard let emotion = detectedEmotion else {
            return "é‚„éœ€è¦æ›´å¤šå°è©±ä¾†äº†è§£ä½ çš„æƒ…ç·’ç‹€æ…‹"
        }
        
        let confidence = Int(emotion.confidence * 100)
        return "æ ¹æ“š AI åˆ†æï¼Œä½ ç¾åœ¨\(emotion.emotionType)ï¼Œå£“åŠ›ç¨‹åº¦æ˜¯\(emotion.stressCategory) (ç½®ä¿¡åº¦ \(confidence)%)"
    }
}
